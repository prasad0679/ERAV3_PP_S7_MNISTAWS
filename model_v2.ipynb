{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMZlsC7DtyNhRaGRW1a/Jzh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bMN_S8pIc4Xo","executionInfo":{"status":"ok","timestamp":1735016278123,"user_tz":-330,"elapsed":3727,"user":{"displayName":"Prasad Pradhan","userId":"02710710309404219784"}},"outputId":"72c1555b-7605-4b99-a428-d281df1529ab"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchvision import datasets, transforms"],"metadata":{"id":"sqb24SyHdFGE","executionInfo":{"status":"ok","timestamp":1735016278124,"user_tz":-330,"elapsed":3,"user":{"displayName":"Prasad Pradhan","userId":"02710710309404219784"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# CUDA?\n","cuda = torch.cuda.is_available()\n","print(\"CUDA Available?\", cuda)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UuHz9PskdIA0","executionInfo":{"status":"ok","timestamp":1735016278124,"user_tz":-330,"elapsed":3,"user":{"displayName":"Prasad Pradhan","userId":"02710710309404219784"}},"outputId":"d022fc49-6ebd-4cfa-f944-28348217bc03"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["CUDA Available? False\n"]}]},{"cell_type":"code","source":["dropout_value = 0.1\n","class Net(nn.Module):\n","    #This defines the structure of the NN.\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        # Input block\n","        self.convblock1 = nn.Sequential(\n","            nn.Conv2d(in_channels=1, out_channels=8, kernel_size=(3, 3), padding=0, bias=False),\n","            nn.ReLU(),\n","            nn.BatchNorm2d(8),\n","            nn.Dropout(dropout_value)\n","        ) # output_size = 26X26X8 | RF : 3\n","\n","        # CONVOLUTION BLOCK 1\n","        self.convblock2 = nn.Sequential(\n","            nn.Conv2d(in_channels=8, out_channels=16, kernel_size=(3, 3), padding=0, bias=False),\n","            nn.ReLU(),\n","            nn.BatchNorm2d(16),\n","            nn.Dropout(dropout_value)\n","        ) # output_size = 24X24X16 | RF : 5\n","\n","        self.convblock3 = nn.Sequential(\n","            nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(3, 3), padding=0, bias=False),\n","            nn.ReLU(),\n","            nn.BatchNorm2d(16),\n","            nn.Dropout(dropout_value)\n","        ) # output_size = 22X22X16 | RF : 7\n","\n","        self.convblock4 = nn.Sequential(\n","            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(3, 3), padding=0, bias=False),\n","            nn.ReLU(),\n","            nn.BatchNorm2d(32),\n","            nn.Dropout(dropout_value)\n","        ) # output_size = 20X20X32 | RF : 9\n","\n","        # TRANSITION BLOCK 1\n","        self.convblock5 = nn.Sequential(\n","            nn.Conv2d(in_channels=32, out_channels=10, kernel_size=(1, 1), padding=0, bias=False),\n","        ) # output_size = 20X20X10 | RF : 9\n","        self.pool1 = nn.MaxPool2d(2, 2) # output_size = 10X10X10 | RF : 10\n","\n","        # CONVOLUTION BLOCK 2\n","        self.convblock6 = nn.Sequential(\n","            nn.Conv2d(in_channels=10, out_channels=16, kernel_size=(3, 3), padding=0, bias=False),\n","            nn.ReLU(),\n","            nn.BatchNorm2d(16),\n","            nn.Dropout(dropout_value)\n","        ) # # output_size = 8X8X16 | RF : 14\n","        self.convblock7 = nn.Sequential(\n","            nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(3, 3), padding=0, bias=False),\n","            nn.ReLU(),\n","            nn.BatchNorm2d(16),\n","            nn.Dropout(dropout_value)\n","        ) # output_size = 6X6X16 | RF : 18\n","\n","        self.convblock8 = nn.Sequential(\n","            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(3, 3), padding=0, bias=False),\n","            nn.ReLU(),\n","            nn.BatchNorm2d(32),\n","            nn.Dropout(dropout_value)\n","        ) # output_size = 4X4X32 | RF : 22\n","\n","        # OUTPUT BLOCK\n","        self.gap = nn.Sequential(\n","            nn.AvgPool2d(kernel_size=4)\n","        ) # output_size = 1X1X32 | RF: 22\n","\n","        self.convblock9 = nn.Sequential(\n","            nn.Conv2d(in_channels=32, out_channels=10, kernel_size=(1, 1), padding=0, bias=False),\n","            # nn.BatchNorm2d(10),\n","            # nn.ReLU(),\n","            # nn.Dropout(dropout_value)\n","        ) # output: 1X1X10 | RF: 26\n","\n","    def forward(self, x):\n","        x = self.convblock1(x)\n","        x = self.convblock2(x)\n","        x = self.convblock3(x)\n","        x = self.convblock4(x)\n","        x = self.convblock5(x)\n","\n","        x = self.pool1(x)\n","\n","        x = self.convblock6(x)\n","        x = self.convblock7(x)\n","        x = self.convblock8(x)\n","\n","        x = self.gap(x)\n","        x = self.convblock9(x)\n","\n","        x = x.view(-1, 10)\n","        x = F.log_softmax(x, dim=1)\n","        return x"],"metadata":{"id":"LwGuesuLN0gY","executionInfo":{"status":"ok","timestamp":1735016448331,"user_tz":-330,"elapsed":700,"user":{"displayName":"Prasad Pradhan","userId":"02710710309404219784"}}},"execution_count":9,"outputs":[]}]}