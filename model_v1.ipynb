{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNR00Ty8XnGhSqxMVMueIOl"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bMN_S8pIc4Xo","executionInfo":{"status":"ok","timestamp":1734978437548,"user_tz":-330,"elapsed":30035,"user":{"displayName":"Prasad Pradhan","userId":"02710710309404219784"}},"outputId":"f6f44426-9f79-46bd-d5ac-9b1d29792e95"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchvision import datasets, transforms"],"metadata":{"id":"sqb24SyHdFGE","executionInfo":{"status":"ok","timestamp":1734978482281,"user_tz":-330,"elapsed":17955,"user":{"displayName":"Prasad Pradhan","userId":"02710710309404219784"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# CUDA?\n","cuda = torch.cuda.is_available()\n","print(\"CUDA Available?\", cuda)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UuHz9PskdIA0","executionInfo":{"status":"ok","timestamp":1734978483232,"user_tz":-330,"elapsed":3,"user":{"displayName":"Prasad Pradhan","userId":"02710710309404219784"}},"outputId":"bd02112b-a80f-42f3-a6e9-5ba18fb0fd92"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["CUDA Available? False\n"]}]},{"cell_type":"code","source":["dropout_value = 0.1\n","class Net(nn.Module):\n","    #This defines the structure of the NN.\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        # Input block\n","        self.convblock1 = nn.Sequential(\n","            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=(3, 3), padding=0, bias=False),\n","            nn.ReLU(),\n","            nn.BatchNorm2d(16),\n","            nn.Dropout(dropout_value)\n","        ) # output_size = 26X26X16 | RF : 3\n","\n","        # CONVOLUTION BLOCK 1\n","        self.convblock2 = nn.Sequential(\n","            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(3, 3), padding=0, bias=False),\n","            nn.ReLU(),\n","            nn.BatchNorm2d(32),\n","            nn.Dropout(dropout_value)\n","        ) # output_size = 24X24X32 | RF : 5\n","\n","        self.convblock3 = nn.Sequential(\n","            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3, 3), padding=0, bias=False),\n","            nn.ReLU(),\n","            nn.BatchNorm2d(64),\n","            nn.Dropout(dropout_value)\n","        ) # output_size = 22X22X64 | RF : 7\n","\n","        self.convblock4 = nn.Sequential(\n","            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3, 3), padding=0, bias=False),\n","            nn.ReLU(),\n","            nn.BatchNorm2d(128),\n","            nn.Dropout(dropout_value)\n","        ) # output_size = 20X20X128 | RF : 9\n","\n","        # TRANSITION BLOCK 1\n","        self.convblock5 = nn.Sequential(\n","            nn.Conv2d(in_channels=128, out_channels=16, kernel_size=(1, 1), padding=0, bias=False),\n","        ) # output_size = 20X20X16 | RF : 9\n","        self.pool1 = nn.MaxPool2d(2, 2) # output_size = 10X10X16 | RF : 10\n","\n","        # CONVOLUTION BLOCK 2\n","        self.convblock6 = nn.Sequential(\n","            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(3, 3), padding=0, bias=False),\n","            nn.ReLU(),\n","            nn.BatchNorm2d(32),\n","            nn.Dropout(dropout_value)\n","        ) # # output_size = 8X8X32 | RF : 14\n","        self.convblock7 = nn.Sequential(\n","            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3, 3), padding=0, bias=False),\n","            nn.ReLU(),\n","            nn.BatchNorm2d(64),\n","            nn.Dropout(dropout_value)\n","        ) # output_size = 6X6X64 | RF : 18\n","\n","        self.convblock8 = nn.Sequential(\n","            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3, 3), padding=0, bias=False),\n","            nn.ReLU(),\n","            nn.BatchNorm2d(128),\n","            nn.Dropout(dropout_value)\n","        ) # output_size = 4X4X128 | RF : 22\n","\n","        # OUTPUT BLOCK\n","        self.gap = nn.Sequential(\n","            nn.AvgPool2d(kernel_size=4)\n","        ) # output_size = 1X1X128 | RF: 22\n","\n","        self.convblock9 = nn.Sequential(\n","            nn.Conv2d(in_channels=128, out_channels=10, kernel_size=(1, 1), padding=0, bias=False),\n","            # nn.BatchNorm2d(10),\n","            # nn.ReLU(),\n","            # nn.Dropout(dropout_value)\n","        ) # output: 1X1X10 | RF: 26\n","\n","    def forward(self, x):\n","        x = self.convblock1(x)\n","        x = self.convblock2(x)\n","        x = self.convblock3(x)\n","        x = self.convblock4(x)\n","        x = self.convblock5(x)\n","\n","        x = self.pool1(x)\n","\n","        x = self.convblock6(x)\n","        x = self.convblock7(x)\n","        x = self.convblock8(x)\n","\n","        x = self.gap(x)\n","        x = self.convblock9(x)\n","\n","        x = x.view(-1, 10)\n","        x = F.log_softmax(x, dim=1)\n","        return x"],"metadata":{"id":"LwGuesuLN0gY","executionInfo":{"status":"ok","timestamp":1734981316081,"user_tz":-330,"elapsed":552,"user":{"displayName":"Prasad Pradhan","userId":"02710710309404219784"}}},"execution_count":6,"outputs":[]}]}